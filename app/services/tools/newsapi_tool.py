"""NewsAPI.org Tool - International news search"""

from typing import Type, Optional
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import os
import requests


class NewsAPIInput(BaseModel):
    """Input schema for NewsAPI search"""
    query: str = Field(..., description="ê²€ìƒ‰ í‚¤ì›Œë“œ/ë¬¸êµ¬")
    from_date: Optional[str] = Field(None, description="ISO8601 ì‹œì‘ ë‚ ì§œ(ì˜ˆ: 2025-08-08)")
    to_date: Optional[str] = Field(None, description="ISO8601 ì¢…ë£Œ ë‚ ì§œ")
    language: Optional[str] = Field(None, description="ì–¸ì–´ ì½”ë“œ, ì˜ˆ: en, ko")
    sort_by: Optional[str] = Field("publishedAt", description="ì •ë ¬: relevancy|popularity|publishedAt")
    page_size: Optional[int] = Field(20, description="í˜ì´ì§€ë‹¹ ê²°ê³¼ìˆ˜(ìµœëŒ€ 100)")


class NewsAPITool(BaseTool):
    """NewsAPI.org everything endpoint wrapper"""

    name: str = "NewsAPI Search"
    description: str = (
        "NewsAPI.orgì˜ /v2/everything ì—”ë“œí¬ì¸íŠ¸ë¡œ êµ­ì œ ë‰´ìŠ¤ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. "
        "í‚¤ì›Œë“œ, ë‚ ì§œ ë²”ìœ„, ì–¸ì–´, ì •ë ¬ì„ ì§€ì›í•©ë‹ˆë‹¤."
    )
    args_schema: Type[BaseModel] = NewsAPIInput

    def _run(
        self,
        query: str,
        from_date: Optional[str] = None,
        to_date: Optional[str] = None,
        language: Optional[str] = None,
        sort_by: Optional[str] = "publishedAt",
        page_size: Optional[int] = 20,
    ) -> str:
        api_key = os.getenv("NEWSAPI_API_KEY")
        if not api_key:
            return "NewsAPI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ NEWSAPI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”."

        url = "https://newsapi.org/v2/everything"
        params = {
            "q": query,
            "sortBy": sort_by or "publishedAt",
            "pageSize": max(1, min(100, page_size or 20)),
        }
        if from_date:
            params["from"] = from_date
        if to_date:
            params["to"] = to_date
        if language:
            params["language"] = language

        headers = {"X-Api-Key": api_key}

        try:
            resp = requests.get(url, params=params, headers=headers, timeout=20)
            if resp.status_code != 200:
                return f"NewsAPI ì˜¤ë¥˜: HTTP {resp.status_code} - {resp.text[:300]}"
            data = resp.json()
            if data.get("status") != "ok":
                return f"NewsAPI ì˜¤ë¥˜: {data}"

            articles = data.get("articles", [])
            if not articles:
                return f"'{query}'ì— ëŒ€í•œ ë‰´ìŠ¤ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

            lines = [
                f"ğŸ“° NewsAPI ê²€ìƒ‰ ê²°ê³¼: '{query}' (ì´ {data.get('totalResults', 0):,}ê±´ ì¤‘ {len(articles)}ê±´ í‘œì‹œ)\n"
            ]
            for i, a in enumerate(articles, 1):
                title = a.get("title") or "ì œëª© ì—†ìŒ"
                source = (a.get("source") or {}).get("name") or "ì¶œì²˜ ë¯¸ìƒ"
                published = a.get("publishedAt") or ""
                desc = a.get("description") or ""
                if len(desc) > 200:
                    desc = desc[:200] + "..."
                url_a = a.get("url") or ""
                lines.append(
                    f"[{i}] {title}\n- ì¶œì²˜: {source}\n- ì¼ì‹œ: {published}\n- ìš”ì•½: {desc}\n- ë§í¬: {url_a}\n"
                )
            return "\n".join(lines)
        except requests.exceptions.RequestException as e:
            return f"NewsAPI ìš”ì²­ ì˜¤ë¥˜: {str(e)}"

