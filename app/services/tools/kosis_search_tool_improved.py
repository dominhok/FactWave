"""KOSIS Search Tool - ê°œì„ ëœ ë²„ì „ (ì˜¤ë¥˜ ìˆ˜ì • ë° ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘)"""

from typing import Type, Optional, Dict, List, Any
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import os
import PublicDataReader as pdr
import pandas as pd
from datetime import datetime, timedelta


class KOSISSearchInput(BaseModel):
    query: str = Field(..., description="ê²€ìƒ‰ì–´ (ì˜ˆ: GDP, ì¸êµ¬, ì‹¤ì—…ë¥ )")
    limit: int = Field(5, description="ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ìµœëŒ€ 20)")
    fetch_data: bool = Field(True, description="í†µê³„ ë°ì´í„°ë„ í•¨ê»˜ ê°€ì ¸ì˜¬ì§€ ì—¬ë¶€")
    years: int = Field(10, description="ìµœê·¼ ëª‡ ë…„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ì§€")


class KOSISSearchTool(BaseTool):
    """KOSIS í†µí•©ê²€ìƒ‰ì„ í†µí•œ ìì—°ì–´ í†µê³„ ê²€ìƒ‰ (ê°œì„ ëœ ë²„ì „)"""

    name: str = "KOSIS_Natural_Search_Improved"
    description: str = (
        "KOSIS í†µê³„ë¥¼ ìì—°ì–´ë¡œ ê²€ìƒ‰í•˜ê³  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. "
        "ì˜ˆ: 'GDP', 'ì¸êµ¬', 'ì‹¤ì—…ë¥ ', 'ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜' ë“±"
    )
    args_schema: Type[BaseModel] = KOSISSearchInput

    def _run(
        self,
        query: str,
        limit: int = 5,
        fetch_data: bool = True,
        years: int = 10
    ) -> str:
        """KOSIS ìì—°ì–´ ê²€ìƒ‰ ì‹¤í–‰ (ê°œì„ ëœ ë²„ì „)"""
        
        # API í‚¤ í™•ì¸ (ë”°ì˜´í‘œ ì œê±°)
        api_key = os.getenv("KOSIS_API_KEY", "").strip('"')
        if not api_key:
            return "âŒ KOSIS API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ KOSIS_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”."

        collected_data = []  # ìˆ˜ì§‘ëœ ëª¨ë“  ë°ì´í„° ì €ì¥
        
        try:
            # PublicDataReader API ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            api = pdr.Kosis(api_key)
            
            # 1ë‹¨ê³„: í†µí•©ê²€ìƒ‰ (ì˜¤ë¥˜ ë°œìƒ ì „ ë¶€ë¶„)
            try:
                # í†µí•©ê²€ìƒ‰ API í˜¸ì¶œ - PublicDataReader ë¬¸ì„œ ê¸°ë°˜
                search_results = api.get_data(
                    "KOSISí†µí•©ê²€ìƒ‰",
                    searchNm=query
                    # sort, startCount, resultCountëŠ” ì„ íƒì‚¬í•­
                )
            except Exception as search_error:
                # í†µí•©ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì§ì ‘ ì•Œë ¤ì§„ í…Œì´ë¸” ê²€ìƒ‰
                print(f"í†µí•©ê²€ìƒ‰ API ì˜¤ë¥˜: {search_error}")
                search_results = self._fallback_search(api, query, limit)
            
            if not isinstance(search_results, pd.DataFrame) or search_results.empty:
                return f"âŒ '{query}'ì— ëŒ€í•œ í†µê³„í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ê²°ê³¼ í¬ë§·íŒ…
            result = f"ğŸ” KOSIS ê²€ìƒ‰: '{query}'\n"
            result += f"ğŸ“Š {len(search_results)}ê°œ í†µê³„í‘œ ë°œê²¬\n\n"
            
            # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ë° ë°ì´í„° ìˆ˜ì§‘
            data_fetched_count = 0
            max_data_fetch = min(3, len(search_results))  # ìµœëŒ€ 3ê°œ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            
            for idx in range(min(len(search_results), limit)):
                row = search_results.iloc[idx]
                
                # ì»¬ëŸ¼ëª… í™•ì¸ (í•œê¸€/ì˜ë¬¸)
                org_id = row.get('ê¸°ê´€ID', row.get('ORG_ID', ''))
                tbl_id = row.get('í†µê³„í‘œID', row.get('TBL_ID', ''))
                tbl_nm = row.get('í†µê³„í‘œëª…', row.get('TBL_NM', ''))
                org_nm = row.get('ê¸°ê´€ëª…', row.get('ORG_NM', ''))
                contents = row.get('í†µê³„í‘œì£¼ìš”ë‚´ìš©', row.get('CONTENTS', ''))
                
                result += f"[{idx + 1}] {tbl_nm}\n"
                result += f"    ê¸°ê´€: {org_nm} ({org_id})\n"
                result += f"    í…Œì´ë¸”ID: {tbl_id}\n"
                
                if contents:
                    content_preview = contents[:100] + "..." if len(contents) > 100 else contents
                    result += f"    ì„¤ëª…: {content_preview}\n"
                
                # ìƒìœ„ 3ê°œ í…Œì´ë¸”ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                if fetch_data and data_fetched_count < max_data_fetch:
                    result += f"\n    ğŸ“ˆ ë°ì´í„° ({years}ë…„ê°„):\n"
                    table_data = self._fetch_table_data_improved(
                        api, org_id, tbl_id, tbl_nm, years
                    )
                    
                    if table_data["success"]:
                        result += table_data["formatted"]
                        collected_data.append({
                            "table_name": tbl_nm,
                            "table_id": tbl_id,
                            "data": table_data["raw_data"]
                        })
                        data_fetched_count += 1
                    else:
                        result += f"    {table_data['error']}\n"
                
                result += "\n"
            
            # ìˆ˜ì§‘ëœ ë°ì´í„° ìš”ì•½
            if collected_data:
                result += "\nğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ìš”ì•½:\n"
                for data_item in collected_data:
                    result += f"  - {data_item['table_name']}: {len(data_item['data'])}ê°œ ë°ì´í„°í¬ì¸íŠ¸\n"
            
            # ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒì )
            if collected_data and fetch_data:
                self._save_collected_data(query, collected_data)
                result += f"\nğŸ’¾ ìƒì„¸ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
            
            return result
            
        except Exception as e:
            return f"âŒ KOSIS API ì˜¤ë¥˜: {str(e)}"
    
    def _fallback_search(self, api, query: str, limit: int) -> pd.DataFrame:
        """í†µí•©ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì•Œë ¤ì§„ í…Œì´ë¸” ì§ì ‘ ê²€ìƒ‰"""
        # GDP ê´€ë ¨ ì•Œë ¤ì§„ í…Œì´ë¸”
        known_tables = {
            "GDP": [
                {"ê¸°ê´€ID": "301", "í†µê³„í‘œID": "DT_200Y001", "í†µê³„í‘œëª…": "êµ­ë‚´ì´ìƒì‚°(ëª…ëª©, ì›í™”í‘œì‹œ)", "ê¸°ê´€ëª…": "í•œêµ­ì€í–‰"},
                {"ê¸°ê´€ID": "301", "í†µê³„í‘œID": "DT_200Y002", "í†µê³„í‘œëª…": "ê²½ì œí™œë™ë³„ GDP", "ê¸°ê´€ëª…": "í•œêµ­ì€í–‰"},
                {"ê¸°ê´€ID": "301", "í†µê³„í‘œID": "DT_200Y003", "í†µê³„í‘œëª…": "ì§€ì¶œí•­ëª©ë³„ GDP", "ê¸°ê´€ëª…": "í•œêµ­ì€í–‰"}
            ],
            "ì‹¤ì—…ë¥ ": [
                {"ê¸°ê´€ID": "101", "í†µê³„í‘œID": "DT_1DA7002S", "í†µê³„í‘œëª…": "ì‹¤ì—…ë¥ ", "ê¸°ê´€ëª…": "í†µê³„ì²­"},
                {"ê¸°ê´€ID": "101", "í†µê³„í‘œID": "DT_1DA7004S", "í†µê³„í‘œëª…": "ê³ ìš©ë¥ ", "ê¸°ê´€ëª…": "í†µê³„ì²­"}
            ],
            "ì¸êµ¬": [
                {"ê¸°ê´€ID": "101", "í†µê³„í‘œID": "DT_1B040A3", "í†µê³„í‘œëª…": "ì£¼ë¯¼ë“±ë¡ì¸êµ¬", "ê¸°ê´€ëª…": "í†µê³„ì²­"},
                {"ê¸°ê´€ID": "101", "í†µê³„í‘œID": "DT_1B040M5", "í†µê³„í‘œëª…": "ì‹œë„ë³„ ì¸êµ¬", "ê¸°ê´€ëª…": "í†µê³„ì²­"}
            ]
        }
        
        # ì¿¼ë¦¬ì™€ ë§¤ì¹­ë˜ëŠ” í…Œì´ë¸” ì°¾ê¸°
        matched_tables = []
        query_lower = query.lower()
        
        for key, tables in known_tables.items():
            if key.lower() in query_lower or query_lower in key.lower():
                matched_tables.extend(tables[:limit])
        
        if matched_tables:
            return pd.DataFrame(matched_tables)
        else:
            return pd.DataFrame()
    
    def _fetch_table_data_improved(
        self, api, org_id: str, tbl_id: str, tbl_nm: str, years: int
    ) -> Dict[str, Any]:
        """ê°œì„ ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° - ë” ë§ì€ ì‹œë„ì™€ ëŒ€ì²´ ë°©ë²•"""
        
        current_year = datetime.now().year
        start_year = current_year - years
        
        # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œë„
        attempts = [
            # ì‹œë„ 1: ì—°ê°„ ë°ì´í„° (ì „ì²´ ê¸°ê°„)
            {
                "params": {
                    "orgId": str(org_id),
                    "tblId": str(tbl_id),
                    "itmId": "ALL",
                    "objL1": "ALL",
                    "objL2": "ALL",
                    "objL3": "ALL",
                    "objL4": "ALL",
                    "objL5": "ALL",
                    "objL6": "ALL",
                    "objL7": "ALL",
                    "objL8": "ALL",
                    "prdSe": "Y",
                    "startPrdDe": str(start_year),
                    "endPrdDe": str(current_year),
                    "apiKey": api.api_key  # apiKey ëª…ì‹œì  ì¶”ê°€
                },
                "description": "ì—°ê°„ ì „ì²´ ê¸°ê°„"
            },
            # ì‹œë„ 2: ìµœê·¼ Nê°œ ì—°ê°„ ë°ì´í„°
            {
                "params": {
                    "orgId": str(org_id),
                    "tblId": str(tbl_id),
                    "itmId": "ALL",
                    "objL1": "ALL",
                    "objL2": "ALL",
                    "prdSe": "Y",
                    "newEstPrdCnt": str(years),
                    "apiKey": api.api_key  # apiKey ëª…ì‹œì  ì¶”ê°€
                },
                "description": f"ìµœê·¼ {years}ë…„"
            },
            # ì‹œë„ 3: ë¶„ê¸° ë°ì´í„°
            {
                "params": {
                    "orgId": str(org_id),
                    "tblId": str(tbl_id),
                    "itmId": "ALL",
                    "objL1": "ALL",
                    "objL2": "ALL",
                    "prdSe": "Q",
                    "newEstPrdCnt": "20",
                    "apiKey": api.api_key  # apiKey ëª…ì‹œì  ì¶”ê°€
                },
                "description": "ìµœê·¼ 20ë¶„ê¸°"
            },
            # ì‹œë„ 4: ì›”ê°„ ë°ì´í„°
            {
                "params": {
                    "orgId": str(org_id),
                    "tblId": str(tbl_id),
                    "itmId": "ALL",
                    "objL1": "ALL",
                    "objL2": "ALL",
                    "prdSe": "M",
                    "newEstPrdCnt": "60",
                    "apiKey": api.api_key  # apiKey ëª…ì‹œì  ì¶”ê°€
                },
                "description": "ìµœê·¼ 60ê°œì›”"
            }
        ]
        
        for attempt in attempts:
            try:
                data = api.get_data("í†µê³„ìë£Œ", **attempt["params"])
                
                if isinstance(data, pd.DataFrame) and not data.empty:
                    # ë°ì´í„° í¬ë§·íŒ…
                    formatted_data, raw_data = self._format_data_improved(data, tbl_nm)
                    
                    if formatted_data:
                        return {
                            "success": True,
                            "formatted": formatted_data,
                            "raw_data": raw_data,
                            "method": attempt["description"]
                        }
            except Exception as e:
                continue
        
        return {
            "success": False,
            "error": "(ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ - ëª¨ë“  ë°©ë²• ì‹œë„í•¨)",
            "raw_data": []
        }
    
    def _format_data_improved(self, data: pd.DataFrame, tbl_nm: str) -> tuple:
        """ê°œì„ ëœ ë°ì´í„° í¬ë§·íŒ… - ë” ë§ì€ ë°ì´í„° í‘œì‹œ"""
        
        # ì£¼ìš” ì»¬ëŸ¼ ì°¾ê¸°
        period_cols = ['PRD_DE', 'PRD_YM', 'ìˆ˜ë¡ì‹œì ', 'PERIOD', 'TIME']
        value_cols = ['DT', 'ìˆ˜ì¹˜ê°’', 'DATA_VALUE', 'VAL', 'VALUE']
        unit_cols = ['UNIT_NM', 'ë‹¨ìœ„ëª…', 'UNIT', 'ë‹¨ìœ„']
        item_cols = ['ITM_NM', 'í•­ëª©ëª…', 'ITEM', 'í•­ëª©']
        c1_cols = ['C1_NM', 'ë¶„ë¥˜1ëª…', 'CLASS1', 'C1', 'ë¶„ë¥˜1']
        c2_cols = ['C2_NM', 'ë¶„ë¥˜2ëª…', 'CLASS2', 'C2', 'ë¶„ë¥˜2']
        
        # ì‹¤ì œ ì»¬ëŸ¼ ì°¾ê¸°
        period_col = next((col for col in period_cols if col in data.columns), None)
        value_col = next((col for col in value_cols if col in data.columns), None)
        unit_col = next((col for col in unit_cols if col in data.columns), None)
        item_col = next((col for col in item_cols if col in data.columns), None)
        c1_col = next((col for col in c1_cols if col in data.columns), None)
        c2_col = next((col for col in c2_cols if col in data.columns), None)
        
        if not period_col or not value_col:
            return "", []
        
        # ë°ì´í„° ì •ë ¬ ë° í•„í„°ë§
        data_sorted = data.sort_values(by=period_col, ascending=False)
        
        # NULLì´ ì•„ë‹Œ ê°’ë§Œ í•„í„°ë§
        data_valid = data_sorted[data_sorted[value_col].notna()]
        
        if data_valid.empty:
            return "", []
        
        # ìµœëŒ€ 20ê°œ ë°ì´í„° í¬ì¸íŠ¸ í‘œì‹œ
        display_limit = min(20, len(data_valid))
        formatted_lines = []
        raw_data = []
        
        # í•­ëª©ë³„ë¡œ ê·¸ë£¹í™” (ìˆëŠ” ê²½ìš°)
        if item_col and item_col in data_valid.columns:
            items = data_valid[item_col].unique()[:3]  # ìµœëŒ€ 3ê°œ í•­ëª©
            
            for item in items:
                item_data = data_valid[data_valid[item_col] == item].head(5)
                if not item_data.empty:
                    formatted_lines.append(f"    [{item}]")
                    
                    for _, row in item_data.iterrows():
                        period = row[period_col]
                        value = row[value_col]
                        
                        # ê°’ í¬ë§·íŒ…
                        try:
                            val = float(value)
                            if "ìœ¨" in tbl_nm or "%" in str(row.get(unit_col, "")):
                                formatted_value = f"{val:.2f}%"
                            elif val > 1e12:
                                formatted_value = f"{val/1e12:.2f}ì¡°"
                            elif val > 1e8:
                                formatted_value = f"{val/1e8:.2f}ì–µ"
                            elif val > 1e4:
                                formatted_value = f"{val/1e4:.1f}ë§Œ"
                            else:
                                formatted_value = f"{val:,.2f}"
                        except:
                            formatted_value = str(value)
                        
                        line = f"      {period}: {formatted_value}"
                        
                        if unit_col and pd.notna(row.get(unit_col)):
                            unit = row[unit_col]
                            if unit and unit not in formatted_value:
                                line += f" {unit}"
                        
                        formatted_lines.append(line)
                        
                        # Raw data ì €ì¥
                        raw_data.append({
                            "period": str(period),
                            "value": value,
                            "item": item,
                            "unit": row.get(unit_col, "")
                        })
        else:
            # í•­ëª© êµ¬ë¶„ ì—†ì´ í‘œì‹œ
            for idx, row in data_valid.head(display_limit).iterrows():
                period = row[period_col]
                value = row[value_col]
                
                # ê°’ í¬ë§·íŒ…
                try:
                    val = float(value)
                    if "ìœ¨" in tbl_nm or "%" in str(row.get(unit_col, "")):
                        formatted_value = f"{val:.2f}%"
                    elif val > 1e12:
                        formatted_value = f"{val/1e12:.2f}ì¡°"
                    elif val > 1e8:
                        formatted_value = f"{val/1e8:.2f}ì–µ"
                    elif val > 1e4:
                        formatted_value = f"{val/1e4:.1f}ë§Œ"
                    else:
                        formatted_value = f"{val:,.2f}"
                except:
                    formatted_value = str(value)
                
                line = f"    {period}: {formatted_value}"
                
                if unit_col and pd.notna(row.get(unit_col)):
                    unit = row[unit_col]
                    if unit and unit not in formatted_value:
                        line += f" {unit}"
                
                if c1_col and pd.notna(row.get(c1_col)):
                    line += f" [{row[c1_col]}]"
                
                formatted_lines.append(line)
                
                # Raw data ì €ì¥
                raw_data.append({
                    "period": str(period),
                    "value": value,
                    "unit": row.get(unit_col, ""),
                    "class1": row.get(c1_col, "")
                })
        
        # ë°ì´í„°ê°€ ë” ìˆìœ¼ë©´ í‘œì‹œ
        if len(data_valid) > display_limit:
            formatted_lines.append(f"    ... ì™¸ {len(data_valid) - display_limit}ê°œ ë°ì´í„°")
        
        return "\n".join(formatted_lines), raw_data
    
    def _save_collected_data(self, query: str, collected_data: List[Dict]):
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        import json
        from pathlib import Path
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        save_dir = Path("kosis_data")
        save_dir.mkdir(exist_ok=True)
        
        # íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = save_dir / f"kosis_{query}_{timestamp}.json"
        
        # ë°ì´í„° ì €ì¥
        save_data = {
            "query": query,
            "timestamp": datetime.now().isoformat(),
            "tables": collected_data
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ ë°ì´í„° ì €ì¥: {filename}")